<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>webDownloader API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>webDownloader</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#!/usr/bin/python
#-----------------------------------------------------------------------------
# Name:        webDownloader.py
#
# Purpose:     This module will provide API to download the webpage components: 
#              html file, image file, javascript file, href link file, host SSL
#              certificate and xxl  based on the input url. The user can list 
#              all the urls he wants to downlad in the file &#34;urllist.txt&#34; .
#
# Author:      Yuancheng Liu
#
# Created:     2021/11/12
# Version:     v_0.1.2
# Copyright:   Copyright (c) 2024 LiuYuancheng
# License:     MIT License 
#-----------------------------------------------------------------------------

import os
import sys
import re
import requests
import ssl
from datetime import datetime
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup

PORT = 443 # port to download the server certificate most server use 443.

# init the not html hyper link type:
SP_LINK_TYPE = (&#39;css&#39;, &#39;png&#39;, &#39;ico&#39;, &#39;jpg&#39;, &#39;jpeg&#39;, &#39;mov&#39;, &#39;ogg&#39;, &#39;gif&#39;, &#39;xml&#39;,&#39;js&#39;)
# init the html maim page pre-fix. the contents will be save in file downloadPage_yyyymmdd_hhmmss.html
PAGE_PRE_FIX = &#39;downloadPage&#39;
URL_RCD_FILE = &#39;urlRcd.txt&#39; # file to record the download info.

#-----------------------------------------------------------------------------
#-----------------------------------------------------------------------------
class webDownloader(object):
    &#34;&#34;&#34; Downloader class.&#34;&#34;&#34;
    def __init__(self, imgFlg=True, linkFlg=True, scriptFlg=True, caFlg=True, 
                 spLinkType=SP_LINK_TYPE):
        &#34;&#34;&#34; Init example: webDownloader(imgFlg=True, linkFlg=True, scriptFlg=True, caFlg=True)
            Args:
                imgFlg (bool, optional): flag to identify whehter download image. Defaults to True.
                linkFlg (bool, optional): flag to identify whehter download all the hyper link contents. Defaults to True.
                scriptFlg (bool, optional): flag to identify whehter download script. Defaults to True.
                caFlg (bool, optional): flag to identify whehter download certificate. Defaults to True.
                spLinkType (list, optional): all the hyper link contents type . Defaults to SP_LINK_TYPE.
        &#34;&#34;&#34;
        self.soup = None
        self.imgFlg = imgFlg
        self.linkFlg = linkFlg
        self.scriptFlg = scriptFlg
        self.caFlg = caFlg
        self.linkType = spLinkType
        self.session = requests.Session()

    #-----------------------------------------------------------------------------
    def _soupfindnSave(self, url, outputFolder, tag2find=&#39;img&#39;, inner=&#39;src&#39;):
        &#34;&#34;&#34; Use the beautiful soup lib to find all the tag in the html contents and 
            download the contents.
        &#34;&#34;&#34;
        pagefolder = os.path.join(outputFolder, tag2find)
        if not os.path.exists(pagefolder): os.mkdir(pagefolder)
        for res in self.soup.findAll(tag2find):   # images, css, etc..
            try:
                if not res.has_attr(inner): continue # check if inner tag (file object) exists
                # clean special chars such as &#39;@, # ? &lt;&gt;&#39;
                filename = re.sub(&#39;\W+&#39;, &#39;.&#39;, os.path.basename(res[inner]))
                # print(&#34;&gt; filename:&#34;, filename)
                # Added the &#39;.html&#39; for the html file in the href
                if tag2find == &#39;link&#39; and (not any(ext in filename for ext in self.linkType)):
                    filename += &#39;.html&#39;
                fileurl = urljoin(url, res.get(inner))
                filepath = os.path.join(pagefolder, filename)
                # rename html ref so can move html and folder of files anywhere
                res[inner] = os.path.join(os.path.basename(pagefolder), filename)
                # create the file.
                if not os.path.isfile(filepath):
                    with open(filepath, &#39;wb&#39;) as file:
                        filebin = self.session.get(fileurl)
                        if len(filebin.content) &gt; 0: # filter the empty file(imge not found)
                            file.write(filebin.content)
            except Exception as err:
                print(err, file=sys.stderr)

    #-----------------------------------------------------------------------------
    def _saveServCA(self, url, pagefolder):
        &#34;&#34;&#34; Parse the host name from the URL then try to download the host&#39;s SSL 
            certificate. 
            Args:
                url (str): web url string.
                pagefileDir (str, optional): path to save the web components.
            Returns:
                [bool]: whether the components saved the successfully.
        &#34;&#34;&#34;
        if &#39;https&#39; in url:
            certfolder = os.path.join(pagefolder, &#39;cert&#39;)
            if not os.path.exists(certfolder): os.mkdir(certfolder)
            caFilepath = os.path.join(certfolder, &#39;cert.der&#39;)
            hostname = urlparse(url).hostname
            with open(caFilepath, &#39;wb&#39;) as f:
                cert = None
                try:
                    cert = ssl.get_server_certificate((hostname, PORT))
                except:
                    print(&#39;&gt;&gt; Error: host: %s is invalid.&#39; % str(hostname))
                    # revert split the host to remove the country section such as &#39;sg&#39;
                    hostname = hostname.rsplit(&#39;.&#39;, 1)[0]
                    cert = ssl.get_server_certificate((hostname, PORT))
                if cert: f.write(ssl.PEM_cert_to_DER_cert(cert)) # write the cert info.
            return True
        else:
            print(&#34;saveServCA() &gt; The url is not a https url, no ssl CA available&#34;)
            return False

    #-----------------------------------------------------------------------------
    def downloadWebContents(self, urlStr, outputDirPath):
        &#34;&#34;&#34; Download the web contents.
            Args:
                urlStr (str): url string
                outputDirPath (str): output folder path.
            Returns:
                bool: true if download successful, else fails.
        &#34;&#34;&#34;
        if not (&#39;http&#39; in urlStr):
            print(&#34;&gt; savePage(): The input url is not valid: %s&#34; %str(urlStr))
            return False
        try:
            response = self.session.get(urlStr)
            self.soup = BeautifulSoup(response.text, features=&#34;lxml&#34;)
            # Create the output folder is the folder not exist.
            if not os.path.exists(outputDirPath): os.mkdir(outputDirPath)
            # save the html page to outputDirPath
            htmlfilePath = os.path.join(outputDirPath, 
                                        PAGE_PRE_FIX+&#39;_&#39;+datetime.now().strftime(&#34;%Y%m%d_%H%M%S&#34;)+&#39;.html&#39;)
            with open(htmlfilePath, &#39;wb&#39;) as file:
                file.write(self.soup.prettify(&#39;utf-8&#39;))
            # download all the image files to outputDirPath/img folder:
            if self.imgFlg:
                self._soupfindnSave(urlStr, outputDirPath, tag2find=&#39;img&#39;, inner=&#39;src&#39;)
            # download all the hyper link files to outputDirPath/link folder:
            if self.linkFlg:
                self._soupfindnSave(urlStr, outputDirPath, tag2find=&#39;link&#39;, inner=&#39;href&#39;)
            # download all the javascript files to outputDirPath/script folder:
            if self.scriptFlg:
                self._soupfindnSave(urlStr, outputDirPath, tag2find=&#39;script&#39;, inner=&#39;src&#39;)
            # download the CA certificate to outputDirPath/cert folder:
            if self.caFlg: self._saveServCA(urlStr, outputDirPath)
            # save the orignal url in the url record file
            urlRcdPath = os.path.join(outputDirPath, URL_RCD_FILE)
            with open(urlRcdPath, &#34;a+&#34;, encoding=&#39;ISO-8859-1&#39;) as f:
                f.write(urlStr)
            return True
        except Exception as err:
            print(&#34;Error &gt; downloadWebContents() create files failed: %s.&#34; % str(err))
            return False

#-----------------------------------------------------------------------------
#-----------------------------------------------------------------------------
def main():
    print(&#34;Start the Web downloader&#34;)
    downloader = webDownloader(imgFlg=True, linkFlg=True, scriptFlg=True, caFlg=True)
    print(&#34;Current working directory is : %s&#34; % os.getcwd())
    dirpath = os.path.dirname(os.path.abspath(__file__))
    outputDir = os.path.join(dirpath, &#39;outputFolder&#39;)
    urlCount = 0 
    while True:
        print(&#34;Input the url:&#34;)
        url = str(input())
        if url in (&#39;exist&#39;, &#39;quit&#39;, &#39;q&#39;, &#39;Q&#39;): break
        urlStr = str(url).strip()
        domain = str(urlparse(urlStr).netloc)
        downloadFolderPath = os.path.join(outputDir, &#39;_&#39;.join((str(urlCount), domain)))
        downloader.downloadWebContents(urlStr, downloadFolderPath)

#-----------------------------------------------------------------------------
if __name__ == &#39;__main__&#39;:
    main()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="webDownloader.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def main():
    print(&#34;Start the Web downloader&#34;)
    downloader = webDownloader(imgFlg=True, linkFlg=True, scriptFlg=True, caFlg=True)
    print(&#34;Current working directory is : %s&#34; % os.getcwd())
    dirpath = os.path.dirname(os.path.abspath(__file__))
    outputDir = os.path.join(dirpath, &#39;outputFolder&#39;)
    urlCount = 0 
    while True:
        print(&#34;Input the url:&#34;)
        url = str(input())
        if url in (&#39;exist&#39;, &#39;quit&#39;, &#39;q&#39;, &#39;Q&#39;): break
        urlStr = str(url).strip()
        domain = str(urlparse(urlStr).netloc)
        downloadFolderPath = os.path.join(outputDir, &#39;_&#39;.join((str(urlCount), domain)))
        downloader.downloadWebContents(urlStr, downloadFolderPath)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="webDownloader.webDownloader"><code class="flex name class">
<span>class <span class="ident">webDownloader</span></span>
<span>(</span><span>imgFlg=True, linkFlg=True, scriptFlg=True, caFlg=True, spLinkType=('css', 'png', 'ico', 'jpg', 'jpeg', 'mov', 'ogg', 'gif', 'xml', 'js'))</span>
</code></dt>
<dd>
<div class="desc"><p>Downloader class.</p>
<p>Init example: webDownloader(imgFlg=True, linkFlg=True, scriptFlg=True, caFlg=True)</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>imgFlg</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>flag to identify whehter download image. Defaults to True.</dd>
<dt><strong><code>linkFlg</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>flag to identify whehter download all the hyper link contents. Defaults to True.</dd>
<dt><strong><code>scriptFlg</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>flag to identify whehter download script. Defaults to True.</dd>
<dt><strong><code>caFlg</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>flag to identify whehter download certificate. Defaults to True.</dd>
<dt><strong><code>spLinkType</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>all the hyper link contents type . Defaults to SP_LINK_TYPE.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class webDownloader(object):
    &#34;&#34;&#34; Downloader class.&#34;&#34;&#34;
    def __init__(self, imgFlg=True, linkFlg=True, scriptFlg=True, caFlg=True, 
                 spLinkType=SP_LINK_TYPE):
        &#34;&#34;&#34; Init example: webDownloader(imgFlg=True, linkFlg=True, scriptFlg=True, caFlg=True)
            Args:
                imgFlg (bool, optional): flag to identify whehter download image. Defaults to True.
                linkFlg (bool, optional): flag to identify whehter download all the hyper link contents. Defaults to True.
                scriptFlg (bool, optional): flag to identify whehter download script. Defaults to True.
                caFlg (bool, optional): flag to identify whehter download certificate. Defaults to True.
                spLinkType (list, optional): all the hyper link contents type . Defaults to SP_LINK_TYPE.
        &#34;&#34;&#34;
        self.soup = None
        self.imgFlg = imgFlg
        self.linkFlg = linkFlg
        self.scriptFlg = scriptFlg
        self.caFlg = caFlg
        self.linkType = spLinkType
        self.session = requests.Session()

    #-----------------------------------------------------------------------------
    def _soupfindnSave(self, url, outputFolder, tag2find=&#39;img&#39;, inner=&#39;src&#39;):
        &#34;&#34;&#34; Use the beautiful soup lib to find all the tag in the html contents and 
            download the contents.
        &#34;&#34;&#34;
        pagefolder = os.path.join(outputFolder, tag2find)
        if not os.path.exists(pagefolder): os.mkdir(pagefolder)
        for res in self.soup.findAll(tag2find):   # images, css, etc..
            try:
                if not res.has_attr(inner): continue # check if inner tag (file object) exists
                # clean special chars such as &#39;@, # ? &lt;&gt;&#39;
                filename = re.sub(&#39;\W+&#39;, &#39;.&#39;, os.path.basename(res[inner]))
                # print(&#34;&gt; filename:&#34;, filename)
                # Added the &#39;.html&#39; for the html file in the href
                if tag2find == &#39;link&#39; and (not any(ext in filename for ext in self.linkType)):
                    filename += &#39;.html&#39;
                fileurl = urljoin(url, res.get(inner))
                filepath = os.path.join(pagefolder, filename)
                # rename html ref so can move html and folder of files anywhere
                res[inner] = os.path.join(os.path.basename(pagefolder), filename)
                # create the file.
                if not os.path.isfile(filepath):
                    with open(filepath, &#39;wb&#39;) as file:
                        filebin = self.session.get(fileurl)
                        if len(filebin.content) &gt; 0: # filter the empty file(imge not found)
                            file.write(filebin.content)
            except Exception as err:
                print(err, file=sys.stderr)

    #-----------------------------------------------------------------------------
    def _saveServCA(self, url, pagefolder):
        &#34;&#34;&#34; Parse the host name from the URL then try to download the host&#39;s SSL 
            certificate. 
            Args:
                url (str): web url string.
                pagefileDir (str, optional): path to save the web components.
            Returns:
                [bool]: whether the components saved the successfully.
        &#34;&#34;&#34;
        if &#39;https&#39; in url:
            certfolder = os.path.join(pagefolder, &#39;cert&#39;)
            if not os.path.exists(certfolder): os.mkdir(certfolder)
            caFilepath = os.path.join(certfolder, &#39;cert.der&#39;)
            hostname = urlparse(url).hostname
            with open(caFilepath, &#39;wb&#39;) as f:
                cert = None
                try:
                    cert = ssl.get_server_certificate((hostname, PORT))
                except:
                    print(&#39;&gt;&gt; Error: host: %s is invalid.&#39; % str(hostname))
                    # revert split the host to remove the country section such as &#39;sg&#39;
                    hostname = hostname.rsplit(&#39;.&#39;, 1)[0]
                    cert = ssl.get_server_certificate((hostname, PORT))
                if cert: f.write(ssl.PEM_cert_to_DER_cert(cert)) # write the cert info.
            return True
        else:
            print(&#34;saveServCA() &gt; The url is not a https url, no ssl CA available&#34;)
            return False

    #-----------------------------------------------------------------------------
    def downloadWebContents(self, urlStr, outputDirPath):
        &#34;&#34;&#34; Download the web contents.
            Args:
                urlStr (str): url string
                outputDirPath (str): output folder path.
            Returns:
                bool: true if download successful, else fails.
        &#34;&#34;&#34;
        if not (&#39;http&#39; in urlStr):
            print(&#34;&gt; savePage(): The input url is not valid: %s&#34; %str(urlStr))
            return False
        try:
            response = self.session.get(urlStr)
            self.soup = BeautifulSoup(response.text, features=&#34;lxml&#34;)
            # Create the output folder is the folder not exist.
            if not os.path.exists(outputDirPath): os.mkdir(outputDirPath)
            # save the html page to outputDirPath
            htmlfilePath = os.path.join(outputDirPath, 
                                        PAGE_PRE_FIX+&#39;_&#39;+datetime.now().strftime(&#34;%Y%m%d_%H%M%S&#34;)+&#39;.html&#39;)
            with open(htmlfilePath, &#39;wb&#39;) as file:
                file.write(self.soup.prettify(&#39;utf-8&#39;))
            # download all the image files to outputDirPath/img folder:
            if self.imgFlg:
                self._soupfindnSave(urlStr, outputDirPath, tag2find=&#39;img&#39;, inner=&#39;src&#39;)
            # download all the hyper link files to outputDirPath/link folder:
            if self.linkFlg:
                self._soupfindnSave(urlStr, outputDirPath, tag2find=&#39;link&#39;, inner=&#39;href&#39;)
            # download all the javascript files to outputDirPath/script folder:
            if self.scriptFlg:
                self._soupfindnSave(urlStr, outputDirPath, tag2find=&#39;script&#39;, inner=&#39;src&#39;)
            # download the CA certificate to outputDirPath/cert folder:
            if self.caFlg: self._saveServCA(urlStr, outputDirPath)
            # save the orignal url in the url record file
            urlRcdPath = os.path.join(outputDirPath, URL_RCD_FILE)
            with open(urlRcdPath, &#34;a+&#34;, encoding=&#39;ISO-8859-1&#39;) as f:
                f.write(urlStr)
            return True
        except Exception as err:
            print(&#34;Error &gt; downloadWebContents() create files failed: %s.&#34; % str(err))
            return False</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="webDownloader.webDownloader.downloadWebContents"><code class="name flex">
<span>def <span class="ident">downloadWebContents</span></span>(<span>self, urlStr, outputDirPath)</span>
</code></dt>
<dd>
<div class="desc"><p>Download the web contents.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>urlStr</code></strong> :&ensp;<code>str</code></dt>
<dd>url string</dd>
<dt><strong><code>outputDirPath</code></strong> :&ensp;<code>str</code></dt>
<dd>output folder path.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>true if download successful, else fails.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def downloadWebContents(self, urlStr, outputDirPath):
    &#34;&#34;&#34; Download the web contents.
        Args:
            urlStr (str): url string
            outputDirPath (str): output folder path.
        Returns:
            bool: true if download successful, else fails.
    &#34;&#34;&#34;
    if not (&#39;http&#39; in urlStr):
        print(&#34;&gt; savePage(): The input url is not valid: %s&#34; %str(urlStr))
        return False
    try:
        response = self.session.get(urlStr)
        self.soup = BeautifulSoup(response.text, features=&#34;lxml&#34;)
        # Create the output folder is the folder not exist.
        if not os.path.exists(outputDirPath): os.mkdir(outputDirPath)
        # save the html page to outputDirPath
        htmlfilePath = os.path.join(outputDirPath, 
                                    PAGE_PRE_FIX+&#39;_&#39;+datetime.now().strftime(&#34;%Y%m%d_%H%M%S&#34;)+&#39;.html&#39;)
        with open(htmlfilePath, &#39;wb&#39;) as file:
            file.write(self.soup.prettify(&#39;utf-8&#39;))
        # download all the image files to outputDirPath/img folder:
        if self.imgFlg:
            self._soupfindnSave(urlStr, outputDirPath, tag2find=&#39;img&#39;, inner=&#39;src&#39;)
        # download all the hyper link files to outputDirPath/link folder:
        if self.linkFlg:
            self._soupfindnSave(urlStr, outputDirPath, tag2find=&#39;link&#39;, inner=&#39;href&#39;)
        # download all the javascript files to outputDirPath/script folder:
        if self.scriptFlg:
            self._soupfindnSave(urlStr, outputDirPath, tag2find=&#39;script&#39;, inner=&#39;src&#39;)
        # download the CA certificate to outputDirPath/cert folder:
        if self.caFlg: self._saveServCA(urlStr, outputDirPath)
        # save the orignal url in the url record file
        urlRcdPath = os.path.join(outputDirPath, URL_RCD_FILE)
        with open(urlRcdPath, &#34;a+&#34;, encoding=&#39;ISO-8859-1&#39;) as f:
            f.write(urlStr)
        return True
    except Exception as err:
        print(&#34;Error &gt; downloadWebContents() create files failed: %s.&#34; % str(err))
        return False</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="webDownloader.main" href="#webDownloader.main">main</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="webDownloader.webDownloader" href="#webDownloader.webDownloader">webDownloader</a></code></h4>
<ul class="">
<li><code><a title="webDownloader.webDownloader.downloadWebContents" href="#webDownloader.webDownloader.downloadWebContents">downloadWebContents</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>